---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
plot(cars)
library(jsonlite)

tweet <- fromJSON('tweets.json')
head(tweet)

```
```{r}
#i - converstion : capital to lowercase for all

tweet$text <- tolower(tweet$text)
head(tweet$text)
```
```{r}
#ii) find number of html

library(stringr)

urlarray <- str_count(tweet$text,"http://")
length(urlarray)
 sum(urlarray) 
```
```{r}
#ii) remove url
library(qdapRegex)
tweet$text <-  rm_url(tweet$text, pattern=pastex("@rm_twitter_url", "@rm_url"))
```
```{r}
#iii) remove username mentioned after @ / word after & and all special characters
library(stringr)
tweet$text <- str_replace_all(tweet$text," "," ")


# Get rid of hashtags
tweet$text <- str_replace_all(tweet$text,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
tweet$text <- str_replace_all(tweet$text,"@[a-z,A-Z]*","")   

tweet$text <- str_replace_all(tweet$text, '&[a-z,A-Z]*', "")
tweet$text <- str_replace_all(tweet$text, '(\U0001[a-z,A-Z]*|&[a-z,A-Z]*)', "")



tweet$text

```


```{r}
#iv) remove stopwords and stemming your datasets
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(tweet$text))
corpus = tm_map(corpus, removeWords, stopwords('en'))
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
 
dtm <- DocumentTermMatrix(corpus)
inspect(dtm)
dim(dtm)
```
```{r}
#5 proprotion calculation
freq <- colSums(as.matrix(dtm))
show_once = sum(freq == 1)
show_less_10 = sum(freq < 10)
total = sum(freq >=1)
once_proportion = show_once / total
ten_proportion = show_less_10 / total

print(once_proportion)
print(ten_proportion)

ord <- order(-freq)
freq[ord[1:10]]

```
```{r,plot}
library(tidyverse)
library(rlang)
tibble(word = names(freq), frequency = freq)
 top_n(10.frequency)
 mutate(word = reorder(word, freqeucny))
 ggplot(aes(word,frequency)) +geom_col()+coord_flip()

```

```{r}
#(b) K means clustering 
set.seed(112)
input = tweet[,c("lat","lng")]
head(tweet)
results = kmeans(input, centers = 3, nstart = 20)


```

```{r}
wssplot <- function(data, nc=15, seed=123){
               wss <- (nrow(data)-1)*sum(apply(data,2,var))
               for (i in 2:nc){
                    set.seed(seed)
                    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
                plot(1:nc, wss, type="b", xlab="Number of groups",
                     ylab="Sum of squares within a group")}

wssplot(input, nc = 20)
```
```{r}
set.seed(112)
input = tweet[,c("lat","lng")]
head(tweet)
results = kmeans(input, centers = 2, nstart = 20)
```
```{r}
dat = tweet[,c('lng','lat')]
plot(dat$lat,dat$lng,,asp=1.2,xlab="Latitude", ylab='longitude',col = results$cluster)
#plotcluster(dat, results$cluster)
```
           
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

